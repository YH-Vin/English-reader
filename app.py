import streamlit as st
from openai import OpenAI
import json
import datetime
import base64
import zlib

# -----------------------------------------------------------------------------
# 1. é¡µé¢ä¸è§†è§‰é…ç½® (å¿…é¡»æ”¾åœ¨ä»£ç ç¬¬ä¸€è¡Œ)
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="DeepRead Pro",
    page_icon="ğŸ“˜",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æç®€ä¸»ä¹‰ CSS æ³¨å…¥ ---
custom_css = """
<style>
    /* å…¨å±€å­—ä½“ä¼˜åŒ– - ç±»ä¼¼ Apple/Notion é£æ ¼ */
    .stApp {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }

    /* éšè— Streamlit é»˜è®¤å¤´éƒ¨å’Œé¡µè„š */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        font-weight: 700 !important;
        letter-spacing: -0.03em !important;
        color: #1a1a1a !important;
    }

    /* æ–‡æœ¬è¾“å…¥æ¡†ç¾åŒ– - æŸ”å’ŒèƒŒæ™¯ä¸è¾¹æ¡† */
    .stTextArea textarea {
        background-color: #f7f9fb !important;
        border: 1px solid #e1e4e8 !important;
        border-radius: 12px !important;
        padding: 15px !important;
        box-shadow: none !important;
        transition: all 0.2s ease;
    }
    .stTextArea textarea:focus {
        border-color: #4dabf7 !important;
        background-color: #ffffff !important;
        box-shadow: 0 0 0 3px rgba(77, 171, 247, 0.1) !important;
    }

    /* æŒ‰é’®æ ·å¼ - æ‰å¹³åŒ– */
    div.stButton > button {
        border-radius: 10px !important;
        font-weight: 600 !important;
        border: none !important;
        padding: 0.5rem 1rem !important;
        transition: transform 0.1s;
    }
    div.stButton > button:active {
        transform: scale(0.98);
    }
    
    /* ç»“æœå±•ç¤ºåŒºçš„åˆ†å‰²çº¿ */
    hr {
        margin: 2em 0 !important;
        border: none !important;
        border-top: 1px solid #eaeaea !important;
    }
    
    /* Toast æ¶ˆæ¯æ ·å¼å¾®è°ƒ */
    .stToast {
        border-radius: 10px !important;
    }
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. çŠ¶æ€ç®¡ç† (Session State)
# -----------------------------------------------------------------------------
if "history" not in st.session_state:
    st.session_state.history = []
if "user_level" not in st.session_state:
    st.session_state.user_level = "Intermediate (B1-B2)"

# -----------------------------------------------------------------------------
# 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°åº“
# -----------------------------------------------------------------------------

def get_api_key():
    """ä¼˜å…ˆä» Secrets è·å– Keyï¼Œå¦åˆ™è¿”å› None"""
    try:
        if "ALIYUN_API_KEY" in st.secrets:
            return st.secrets["ALIYUN_API_KEY"]
    except FileNotFoundError:
        pass # æœ¬åœ°è¿è¡Œä¸”æ—  secrets.toml æ—¶å¿½ç•¥
    return None

# --- å­˜æ¡£/è¯»æ¡£é»‘ç§‘æŠ€ ---
def generate_save_token(data):
    """å°†å†å²æ•°æ®å‹ç¼©å¹¶ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²"""
    if not data: return ""
    try:
        json_str = json.dumps(data)
        compressed = zlib.compress(json_str.encode('utf-8'))
        return base64.b64encode(compressed).decode('utf-8')
    except Exception as e:
        st.error(f"Backup Error: {e}")
        return ""

def load_save_token(token):
    """è§£ç  Base64 å¹¶è§£å‹æ¢å¤æ•°æ®"""
    try:
        decoded = base64.b64decode(token)
        json_str = zlib.decompress(decoded).decode('utf-8')
        return json.loads(json_str)
    except Exception:
        return None

# --- AI åˆ†ææ ¸å¿ƒ ---
def analyze_text_pro(client, text, level, model):
    """è°ƒç”¨ API è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¼ºåˆ¶ JSON è¾“å‡º"""
    prompt = f"""
    You are an elite English Linguistics Professor. Analyze the provided text for a student at level: {level}.
    
    GOAL: Produce a structured learning guide like a high-quality textbook.
    
    OUTPUT FORMAT: Return STRICT JSON with these keys:
    1. "main_idea": Concise summary (2-3 sentences).
    2. "explanation": List of objects (keys: "title", "original", "meaning"). Focus on deep comprehension.
    3. "grammar": List of objects (keys: "title", "original", "breakdown"). Explain syntax/structure.
    4. "vocabulary": List of objects (keys: "word", "ipa", "definition", "context"). Max 6 hard words. Include IPA pronunciation.

    Original Text:
    {text}
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a JSON-speaking Linguistics Professor."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2, # ä½æ¸©åº¦ä¿è¯ JSON æ ¼å¼ç¨³å®š
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except json.JSONDecodeError:
        return {"error": "AI è¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡è¯•ã€‚"}
    except Exception as e:
        return {"error": str(e)}

# -----------------------------------------------------------------------------
# 4. ä¾§è¾¹æ  (è®¾ç½® & å¤‡ä»½)
# -----------------------------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    # 1. API Key å¤„ç†
    api_key = get_api_key()
    if not api_key:
        api_key = st.text_input("ğŸ”‘ API Key", type="password", placeholder="Paste Aliyun Key here")
        if not api_key:
            st.warning("âš ï¸ è¯·è¾“å…¥ Key ä»¥ä½¿ç”¨")
    
    st.divider()
    
    # 2. éš¾åº¦é€‰æ‹©
    st.subheader("ğŸ‘¤ User Level")
    st.session_state.user_level = st.selectbox(
        "Select Target Level:",
        ["Beginner (A1-A2)", "Intermediate (B1-B2)", "Advanced (C1-C2)"],
        index=1
    )
    
    st.divider()
    
    # 3. å¤‡ä»½/æ¢å¤ç³»ç»Ÿ
    with st.expander("ğŸ’¾ Backup / Restore", expanded=False):
        st.caption("é˜²æ­¢æ•°æ®ä¸¢å¤±ï¼Œè¯·å®šæœŸå¤‡ä»½")
        
        # å¯¼å‡º
        if st.session_state.history:
            token = generate_save_token(st.session_state.history)
            st.markdown("**Export Token:**")
            st.code(token, language="text")
            st.caption("ğŸ‘† å…¨é€‰å¤åˆ¶ï¼Œå­˜å…¥å¤‡å¿˜å½•ã€‚")
        else:
            st.info("æš‚æ— è®°å½•å¯å¯¼å‡º")
            
        st.markdown("---")
        
        # å¯¼å…¥
        restore_token = st.text_input("Import Token:", placeholder="Paste token here...", label_visibility="collapsed")
        if st.button("ğŸ”„ Restore Data", use_container_width=True):
            data = load_save_token(restore_token)
            if data:
                st.session_state.history = data
                st.toast("âœ… æ•°æ®æ¢å¤æˆåŠŸï¼", icon="ğŸ‰")
                st.rerun()
            else:
                st.error("æ— æ•ˆçš„å­˜æ¡£ç ")

# -----------------------------------------------------------------------------
# 5. ä¸»ç•Œé¢ (Tabs)
# -----------------------------------------------------------------------------
st.title("ğŸ“˜ DeepRead Pro")
st.caption("Your AI-Powered Linguistics Tutor")

tab_analysis, tab_library = st.tabs(["âœ¨ Deep Analysis", "ğŸ“š My Library"])

# === Tab 1: æ·±åº¦åˆ†æ ===
with tab_analysis:
    # --- ğŸ“± æ‰‹æœºç«¯æç¤º (çº¢è‰²é†’ç›®æ¨ªå¹…) ---
    st.markdown(
        """
        <div style='background-color: #fff0f0; padding: 12px; border-radius: 8px; border-left: 5px solid #ff4b4b; margin-bottom: 25px;'>
            <strong style='color: #d8000c;'>âš ï¸ æ‰‹æœºç”¨æˆ·è¯·æ³¨æ„ï¼š</strong>
            <span style='color: #333; font-size: 0.95em;'>è¯·ç‚¹å‡»å·¦ä¸Šè§’ <b>></b> ç®­å¤´å±•å¼€è®¾ç½®ï¼Œæˆ–åœ¨æµè§ˆå™¨èœå•é€‰æ‹©<b>â€œè¯·æ±‚æ¡Œé¢ç½‘ç«™â€</b>ä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚</span>
        </div>
        """,
        unsafe_allow_html=True
    )
    # ----------------------------------

    col_in, col_out = st.columns([1, 1.1])
    
    with col_in:
        st.markdown("#### Input Text")
        source_text = st.text_area(
            "Content", 
            height=350, 
            placeholder="Paste English text here (e.g. from The Economist, NYT)...",
            label_visibility="collapsed"
        )
        
        # åº•éƒ¨æ“ä½œæ 
        c1, c2, c3 = st.columns([1.5, 1, 1])
        with c1:
            model = st.selectbox("Model", ["qwen-plus", "qwen-max"], label_visibility="collapsed")
        with c2:
            # æ¸…ç©ºæŒ‰é’®
            if st.button("ğŸ—‘ï¸ Clear", use_container_width=True):
                # è¿™æ˜¯ä¸€ä¸ªç®€æ˜“æ¸…ç©ºæ–¹å¼ï¼Œéœ€é…åˆ st.rerun() æˆ–è€…æ˜¯è®©ç”¨æˆ·æ‰‹åŠ¨åˆ 
                pass 
        with c3:
            analyze_btn = st.button("Analyze ğŸš€", type="primary", use_container_width=True)

    with col_out:
        st.markdown("#### Insight")
        result_box = st.container()

    # è§¦å‘é€»è¾‘
    if analyze_btn:
        if not api_key:
            st.toast("ğŸš« Please enter API Key first.", icon="ğŸ”’")
        elif not source_text:
            st.toast("âœï¸ Please paste some text.", icon="ğŸ“")
        else:
            with result_box:
                with st.spinner("Analyzing structure, grammar, and context..."):
                    # åˆå§‹åŒ–å®¢æˆ·ç«¯
                    try:
                        client = OpenAI(
                            api_key=api_key, 
                            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
                        )
                        
                        # æ‰§è¡Œåˆ†æ
                        data = analyze_text_pro(client, source_text, st.session_state.user_level, model)
                        
                        if "error" in data:
                            st.error(f"Analysis Failed: {data['error']}")
                        else:
                            # -----------------------------------------------
                            # æ„å»º Markdown è¾“å‡º (æ•™ç§‘ä¹¦é£æ ¼)
                            # -----------------------------------------------
                            md_content = f"### **Main Idea**\n{data.get('main_idea', 'No summary available.')}\n\n"
                            
                            md_content += "---\n### **Detailed Explanation**\n\n"
                            for i, item in enumerate(data.get('explanation', []), 1):
                                md_content += f"**{i}. {item['title']}**\n"
                                md_content += f"> *Original: \"{item['original']}\"*\n\n"
                                md_content += f"*   **Meaning:** {item['meaning']}\n\n"
                            
                            md_content += "---\n### **Grammar Breakdown**\n\n"
                            for i, item in enumerate(data.get('grammar', []), 1):
                                md_content += f"**{i}. {item['title']}**\n"
                                md_content += f"> *\"{item['original']}\"*\n\n"
                                md_content += f"*   **Analysis:** {item['breakdown']}\n\n"
                                
                            md_content += "---\n### **Vocabulary**\n\n"
                            for i, item in enumerate(data.get('vocabulary', []), 1):
                                md_content += f"**{i}. {item['word']}** `{item.get('ipa', '')}`\n"
                                md_content += f"*   **Def:** {item['definition']}\n"
                                md_content += f"*   **Ctx:** {item['context']}\n\n"

                            # å±•ç¤ºç»“æœ
                            st.markdown(md_content)
                            
                            # è‡ªåŠ¨å­˜å…¥å†å²
                            record = {
                                "time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M"),
                                "original": source_text,
                                "markdown": md_content
                            }
                            st.session_state.history.insert(0, record)
                            st.toast("âœ… Saved to Library!", icon="ğŸ’¾")
                            
                    except Exception as e:
                        st.error(f"Connection Error: {e}")

# === Tab 2: å†å²èµ„æ–™åº“ ===
with tab_library:
    st.markdown("#### ğŸ—‚ï¸ Knowledge Base")
    
    if not st.session_state.history:
        st.info("No records found. Go to 'Deep Analysis' to start.")
    else:
        # å·¥å…·æ 
        col_tools, _ = st.columns([1, 4])
        with col_tools:
            if st.button("ğŸ—‘ï¸ Clear All History", type="secondary"):
                st.session_state.history = []
                st.rerun()

        st.divider()
        
        # å¯¼å‡ºé€‰æ‹©é€»è¾‘
        selected_records = []
        for i, note in enumerate(st.session_state.history):
            with st.container():
                # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€ï¼šå¤é€‰æ¡† + æŠ˜å é¢æ¿
                c_check, c_content = st.columns([0.05, 0.95])
                with c_check:
                    if st.checkbox("", key=f"check_{i}"):
                        selected_records.append(note)
                with c_content:
                    with st.expander(f"ğŸ“… {note['time']} - {note['original'][:50]}..."):
                        st.markdown(note['markdown'])
            st.divider() # åˆ†å‰²çº¿
            
        # æµ®åŠ¨/åº•éƒ¨å¯¼å‡ºæŒ‰é’®
        if selected_records:
            st.success(f"Selected {len(selected_records)} notes.")
            
            # ç”Ÿæˆæœ€ç»ˆçš„ Markdown æ–‡ä»¶å†…å®¹
            final_export = f"# DeepRead Study Notes\nGenerated: {datetime.datetime.now().strftime('%Y-%m-%d')}\n\n"
            for note in selected_records:
                final_export += f"## Record: {note['time']}\n"
                final_export += f"{note['markdown']}\n"
                final_export += "\n========================================\n\n"
            
            st.download_button(
                label="ğŸ“¥ Download Markdown (Print-Ready)",
                data=final_export,
                file_name=f"DeepRead_Notes_{datetime.datetime.now().strftime('%Y%m%d')}.md",
                mime="text/markdown",
                type="primary"
            )
